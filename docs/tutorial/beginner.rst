##################################################
Beginner Tutorial - Set up & Running One Algorithm
##################################################

TODO: add an explanation of this tutorial

Step 0: Clone the SPRAS repository, set up the environment, and run Docker
==========================================================================

0.1 Start Docker
----------------

Launch Docker Desktop and wait until it says "Docker is running".

0.2 Clone the SPRAS repository
-------------------------------

Visit the `SPRAS github repository <https://github.com/Reed-CompBio/spras>`__ and clone it locally

0.3 Set up the SPRAS environment
-------------------------------------

From the root directory of the SPRAS repository, create and activate the Conda environment:

.. code:: bash

    conda env create -f environment.yml
    conda activate spras
    python -m pip install .

0.4 Test the installation
-------------------------

Run the following command to confirm that SPRAS has been set up successfully from the command line:

.. code:: bash

   python -c "import spras; print('SPRAS import successful')"

Step 1: Overview of the SPRAS Folder Structure
==============================================

After cloning SPRAS, you will find four main folders that organize everything needed to run and analyze workflows.

.. code-block:: text

   spras/
   ├── .snakemake/
   │   └── log/
   │       └── ... snakemake log files ...
   ├── config/
   │   └── ... other configs ...
   ├── inputs/
   │   └── ... input files ...
   ├── outputs/
   │   └── ... output files ...

.snakemake/
-----------

The log/ directory contains records of all Snakemake jobs that were executed for the SPRAS run, including any errors encountered during those runs.

config/
-------

Holds configuration files (YAML) that define which algorithms to run, what datasets to use, and which analyses to perform.

input/
------

Contains the input data files, such as interactome edge files and input nodes. This is where you can place your own datasets when running custom experiments.

output/
-------

Stores all results generated by SPRAS. Subfolders are created automatically for each run, and their structure can be controlled through the configuration file.

By default, the directories are set to config/, input/, and output/. The config/, input/, and output/ folders can be placed anywhere within the SPRAS repository. Their input/ and output/ locations can be updated in the configuration file, and the configuration file itself can be found by providing its path when running SPRAS.

SPRAS has additional files and directories to use during runs. However, for most users, and for the purposes of this tutorial, it isn’t necessary to fully understand them.

Step 2: Explanation of Configuration File
=========================================

A configuration file controls how SPRAS runs.  It defines which algorithms to run, the parameters to use, the datasets and gold standards to include, the analyses to perform after reconstruction, and the container settings for execution. Think of it as the control center for the workflow.

SPRAS uses Snakemake, a workflow manager, together with Docker, containerized software, to read the configuration file and execute a SPRAS workflow. During a run, Snakemake will automatically fetch any missing Docker images as long as Docker is running. Snakemake considers a task from the configuration file complete once the expected output files are present in the output directory. As a result, rerunning the same configuration file may do nothing if those files already exist. If you want to continue running or rerun SPRAS with the same configuration file, remove the output directory (or its contents) or update the configuration file to trigger Snakemake to generate new results.

For this part of the tutorial, we’ll use a pre-defined configuration file. 
Download it here: :download:`Beginner Config File <../_static/config/beginner.yaml>`

Save the file into the config/ folder of your SPRAS installation.
After adding this file, SPRAS will use the configuration to set up and reference your directory structure, which should now look like this:

.. code-block:: text

   spras/
   ├── .snakemake/
   │   └── log/
   │       └── ... snakemake log files ...
   ├── config/
   │   └── basic.yaml
   ├── inputs/
   │   ├── phosphosite-irefindex13.0-uniprot.txt # pre-defined in SPRAS already
   │   └── tps-egfr-prizes.txt # pre-defined in SPRAS already
   ├── outputs/
   │   └── basic/
   │       └── ... output files ...


Here’s an overview of the major sections looking at config/basic.yaml:

Algorithms
-----------


.. code-block:: text
    
    algorithms:
    - name: "pathlinker"
        params:
            include: true
            run1:
                k: 1
            run2:
                k: 10
            run3:
                k: [100, 400]


When defining an algorithm in the configuration file, its name must match one of the supported wrapped algorithms within in SPRAS (I'll introduce the list of supported algorithms in the intermediate tutorial). Each algorithm includes an include flag, which you set to true to have Snakemake run it, or false to disable it. 

The algorithm's parameters are grouped into one or more run blocks (e.g.  run1, run2, …). Within each run block, parameters are specified as key-value pairs. To define N runs, you can either create N separate run blocks, each with single parameter values, or use parameter lists within one (or multiple) run blocks, where the Cartesian product of those lists generates N parameter combinations. Each unique parameter combination is executed only once for the chosen algorithm, even if the same combination is defined multiple times. All parameter keys must be valid for that algorithm; unknown keys and missing required keys will cause SPRAS to fail.

Datasets
--------

.. code-block:: text

    datasets:
    - 
        label: egfr
        node_files: ["tps-egfr-prizes.txt"]
        edge_files: ["phosphosite-irefindex13.0-uniprot.txt"]
        other_files: []
        data_dir: "input"
    
In the configuration file, datasets are defined under the datasets section. Each dataset you define will be run against all of the algorithms specified in the configuration file. Each dataset entry begins with a label, which uniquely identifies it throughout the SPRAS workflow and outputs. The dataset must include the following types of files:

- node_files: Input files listing the “prizes” or important starting nodes ("sources" or "targets") for the algorithm
- edge_files: Input interactome or network file that defines the relationships between nodes
- other_files: A placefolder for potential need for future delevelopment (double check if this is required)
- data_dir: The file path of the directory where the input dataset files are located

.. This example shows a dataset named egfr that provides both a prize node file and a network edge file, both of which will be used by SPRAS when running the chosen algorithms.

Reconstruction Settings
-----------------------

.. code-block:: text

    reconstruction_settings:
    locations:
        reconstruction_dir: "output/basic"

The reconstruction_settings section controls where results are stored. In the configuration file, you specify the output directory with reconstruction_dir, which tells SPRAS where to save the reconstructed networks (in this example, output/basic). When working with multiple configuration files, you can set different paths for reconstruction_dir to keep results separated. If not specified, all results will be saved to the default directory output/.

Analysis
--------

.. code-block:: text

    analysis:
    summary:
        include: true
    cytoscape:
        include: true


SPRAS includes multiple downstream analyses that can be toggled on or off directly in the configuration file. When enabled, these analyses run for each dataset and provide summaries or visualizations of the results produced by all enabled algorithms.

In this example:

- summary computes statistics for each algorithm’s parameter combination output, generating a summary file for all reconstructed subnetworks for each dataset.
- cytoscape creates a Cytoscape session file (.cys) containing all reconstructed subnetworks for each dataset, making it easy to upload and visualize them directly in Cytoscape.


Step 3: Running SPRAS on a provided example dataset 
====================================================

From the root directory spras/ (not spras/spras, this holds the code to run spras), run the command:

.. code:: bash

    snakemake --cores 1 --configfile config/beginner.yaml

my Subsection
-----------------
My Sub-subsection
^^^^^^^^^^^^^^^^^
- egfr 
- one algorithm
- three different preset combos
    - run one then 2 at a time, then describe what is happening in the output files and the caching
- then run the analysese and explain what is happening 
(what is happening based on the logs (what is run/rerun), what the outputs are (pathway vs raw-pathway) (hashed parameters) (folders) (the other files that are not outputs))

Step #: Understanding the Outputs / Visulizing the Outputs
==========================================================

