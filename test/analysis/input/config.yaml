hash_length: 7

containers:
  framework: docker
  unpack_singularity: false
  registry:
    base_url: docker.io
    owner: reedcompbio

algorithms:
  - name: "pathlinker"
    include: true
    runs:
      run1:
        k: range(100,201,100)

  - name: "omicsintegrator1"
    include: true
    runs:
      run1:
        b: [5, 6]
        w: np.linspace(0,5,2)
        d: [10]
        dummy_mode: ["file"]

  - name: "omicsintegrator2"
    include: true
    runs:
      run1:
        b: [4]
        g: [0]
      run2:
        b: [2]
        g: [3]

  - name: "meo"
    include: true
    runs:
      run1:
        max_path_length: [3]
        local_search: [true]
        rand_restarts: [10]

  - name: "mincostflow"
    include: true
    runs:
      run1:
        flow: [1] # The flow must be an int
        capacity: [1]

  - name: "allpairs"
    include: true

  - name: "domino"
    include: true
    runs:
      run1:
        slice_threshold: [0.3]
        module_threshold: [0.05]

# Here we specify which pathways to run and other file location information.
# DataLoader.py can currently only load a single dataset
# Assume that if a dataset label does not change, the lists of associated input files do not change
datasets:
  - # Labels can only contain letters, numbers, or underscores
    label: data0
    node_files: ["node-prizes.txt", "sources.txt", "targets.txt"]
    # DataLoader.py can currently only load a single edge file, which is the primary network
    edge_files: ["network.txt"]
    # Placeholder
    other_files: []
    # Relative path from the spras directory
    data_dir: "input"

gold_standards:
  - # Labels can only contain letters, numbers, or underscores
    label: gs0
    node_files: ["gs_nodes0.txt"]
    data_dir: "input"
    # List of dataset labels to compare with the specific gold standard dataset
    dataset_labels: ["data0"]

# If we want to reconstruct then we should set run to true.
reconstruction_settings:
  #set where everything is saved
  locations:
    #place the save path here
    reconstruction_dir: "output"

analysis:
  # Create one summary per pathway file and a single summary table for all pathways for each dataset
  summary:
    include: true
  # Create Cytoscape session file with all pathway graphs for each dataset
  cytoscape:
    include: true
  # The following analysis options also have an `aggregate_per_algorithm` option,
  # which adds the respective analysis to an algorithm as a whole.
  # This will only run if the adjacent `include` is true.

  # Principle component analysis of the pathway output files
  pca:
    include: false
    aggregate_per_algorithm: false
    pca_chosen:
      include: false
      aggregate_per_algorithm: false
    # specify how many principal components to calculate
    components: 2
    # boolean to show the labels on the pca graph
    labels: true
    # controls whether kernel density estimation (KDE) is computed and visualized on top of PCA plots.
    # the coordinates of the KDE maximum (kde_peak) are also saved to the PCA coordinates output file.
    # KDE needs to be run in order to select a parameter combination with PCA because the maximum kernel density is used
    # to pick the 'best' parameter combination.
    kde: true
    # removes empty pathways from consideration in ml analysis
    remove_empty_pathways: false
  # Hierarchical agglomerative clustering analysis of the pathway output files
  hac:
    include: false
    aggregate_per_algorithm: false
    # 'ward', 'complete', 'average', 'single'
    # if linkage: ward, must use metric: euclidean
    linkage: 'ward'
    # 'euclidean', 'manhattan', 'cosine'
    metric: 'euclidean'
  # Ensembling pathway output
  ensemble:
    include: false
    aggregate_per_algorithm: true
    evaluation:
      include: false
      aggregate_per_algorithm: false
  evaluation:
    # evaluation per dataset-goldstandard pair.
    # This evaluation specifically generates precision-recall curves:
    # to run evaluation on top of the other options, see the respective `evaluation` blocks under the other analyses.
    include: false
    aggregate_per_algorithm: false
