############################################################
# A submit file to demonstrate running SPRAS in the OSPool #
############################################################

############################################################
#  Define a few macros we use throughout the submit file   #
############################################################
CONFIG_FILE = example_config.yaml
NUM_PROCS = 4
# Paths to input data and Snakefile.
INPUT_DIR = ../../input
SNAKEFILE = ../../Snakefile

############################################################
# Specify that the workflow should run in the SPRAS        #
# container. In the OSPool, this image is usually          #
# converted automatically to an Apptainer/Singularity      #
# image, which is why the example config has               #
# `unpack_singularity = true`.                             #
############################################################
universe = container
container_image = docker://reedcompbio/spras:v0.1.0
# container_image = spras.sif


############################################################
# Specify names for log/stdout/stderr files generated by   #
# HTCondor.                                                #
# NOTE: You should `mkdir logs/` before running, or the    #
# spras_$(Cluster).log file won't be available.            #
############################################################
log = logs/spras_$(Cluster)_$(Process).log
output = logs/spras_$(Cluster)_$(Process).out
error = logs/spras_$(Cluster)_$(Process).err

############################################################
# Specify the script to run inside the container. This is  #
# simply a wrapper on the Snakefile.                       #
############################################################
executable = spras.sh
arguments = "--cores $(NUM_PROCS) --configfile $(CONFIG_FILE) --retries 3"

############################################################
#        Handle transferring required inputs/outputs       #
############################################################
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_input_files = $(CONFIG_FILE), $(INPUT_DIR), $(SNAKEFILE)
# The output directory should match whatever you configure in your configfile.
transfer_output_files = output

############################################################
# System specifications. Be sure to request enough disk to #
# hold any additional containers that might be downloaded  #
# and unpacked as part of the workflow.                    #
############################################################
request_cpus = $(NUM_PROCS)
request_memory = 8GB
request_disk = 16GB

############################################################
# Specify a batch name that we can use to identify the     #
# workflow via `condor_q`.                                 #
############################################################
JobBatchName = "SPRAS-workflow-OSPool"

############################################################
# Indicate that we want to run in the OSPool. This is only #
# needed if running from CHTC. If running from an OSPool   #
# AP, omit this line.                                      #
############################################################
+WantGlideIn = true 

############################################################
# Not all Execution Points in the OSPool will have         #
# Apptainer (formerly Singularity) installed, but this is  #
# a requirement to run SPRAS (since the OSPool is not      #
# Docker friendly). To make sure we land somewhere with    #
# Apptainer, we add it as a job requirement. If running    #
# this submit file from CHTC, we also need a requirement   #
# to prevent landing on a CHTC Execution Point.            #
############################################################
requirements = (HAS_SINGULARITY == True) && (Poolname =!= "CHTC")

# Queue the job
queue 1